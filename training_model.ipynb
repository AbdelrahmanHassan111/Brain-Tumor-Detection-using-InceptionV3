{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1222 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    " keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_data_dir = 'D:\\\\brain-tumor-detection-master\\\\brain_tumor\\\\Training' #location of training data\n",
    "validation_data_dir = 'D:\\\\brain-tumor-detection-master\\\\brain_tumor\\\\Validation' #location of validation data\n",
    "img_width , img_height = 299 , 299\n",
    "# number of samples used for determining the samples_per_epoch\n",
    "nb_train_samples = 1222\n",
    "nb_validation_samples = 168\n",
    "epochs = 20\n",
    "batch_size = 5  \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,            # normalize pixel values to [0,1]\n",
    "        shear_range=0.2,      \n",
    "        zoom_range=0.2,    \n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)  \n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "         rescale=1./255)       # normalize pixel values to [0,1]\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rakha_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rakha_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained InceptionV3 model\n",
    "img_width, img_height = 299, 299\n",
    "base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "# Build the top layers for your model\n",
    "model_top = Sequential()\n",
    "model_top.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:], data_format=None))\n",
    "model_top.add(Dense(256, activation='relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Combine the base model with the top layers\n",
    "model = Model(inputs=base_model.input, outputs=model_top(base_model.output))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_weights('C:\\\\Users\\\\rakha_1\\\\Downloads\\\\brain-tumor-detection-master\\\\inceptionv3_model.h5')  # Replace with the actual path to your trained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\rakha_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rakha_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "244/244 [==============================] - 274s 1s/step - loss: 0.0890 - accuracy: 0.9680 - val_loss: 0.0568 - val_accuracy: 0.9879\n",
      "Epoch 2/20\n",
      "244/244 [==============================] - 241s 986ms/step - loss: 0.0938 - accuracy: 0.9704 - val_loss: 0.0923 - val_accuracy: 0.9697\n",
      "Epoch 3/20\n",
      "244/244 [==============================] - 238s 976ms/step - loss: 0.0418 - accuracy: 0.9844 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "244/244 [==============================] - 238s 974ms/step - loss: 0.0706 - accuracy: 0.9877 - val_loss: 0.0760 - val_accuracy: 0.9818\n",
      "Epoch 5/20\n",
      "244/244 [==============================] - 240s 982ms/step - loss: 0.0549 - accuracy: 0.9869 - val_loss: 0.0313 - val_accuracy: 0.9879\n",
      "Epoch 6/20\n",
      "244/244 [==============================] - 241s 988ms/step - loss: 0.0986 - accuracy: 0.9819 - val_loss: 0.0965 - val_accuracy: 0.9697\n",
      "Epoch 7/20\n",
      "244/244 [==============================] - 239s 977ms/step - loss: 0.0180 - accuracy: 0.9918 - val_loss: 6.1324e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "244/244 [==============================] - 238s 976ms/step - loss: 0.0336 - accuracy: 0.9934 - val_loss: 3.6568e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "244/244 [==============================] - 239s 980ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "244/244 [==============================] - 240s 984ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "244/244 [==============================] - 238s 974ms/step - loss: 0.0397 - accuracy: 0.9869 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "244/244 [==============================] - 256s 1s/step - loss: 0.1021 - accuracy: 0.9811 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "244/244 [==============================] - 284s 1s/step - loss: 0.0529 - accuracy: 0.9885 - val_loss: 9.0211e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "244/244 [==============================] - 284s 1s/step - loss: 0.0502 - accuracy: 0.9910 - val_loss: 7.2392e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "244/244 [==============================] - 284s 1s/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.0157 - val_accuracy: 0.9939\n",
      "Epoch 16/20\n",
      "244/244 [==============================] - 286s 1s/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 6.5495e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "244/244 [==============================] - 286s 1s/step - loss: 0.0597 - accuracy: 0.9877 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "244/244 [==============================] - 284s 1s/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.0410 - val_accuracy: 0.9879\n",
      "Epoch 19/20\n",
      "244/244 [==============================] - 284s 1s/step - loss: 0.0569 - accuracy: 0.9877 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "244/244 [==============================] - 286s 1s/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 3.2712e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rakha_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model (including architecture, optimizer, and learned weights)\n",
    "model.save('brain_tumor_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (including architecture, optimizer, and learned weights)\n",
    "model.save('brain_tumor_trained_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
